# -*- coding: utf-8 -*-
"""Preprocess the text using NLP libraries like NLTK or SpaCy (tokenize, clean, etc.).

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1juXFWSTvq_qALkHGH4HVssA8uYs_rqzI
"""

# âœ… Text Preprocessing using SpaCy (No punkt_tab errors)

# Step 1: Install SpaCy and download English model
!pip install -U spacy --quiet
!python -m spacy download en_core_web_sm

# Step 2: Import libraries
import spacy

# Load SpaCy English model
nlp = spacy.load("en_core_web_sm")

# Step 3: Sample text
text = "Natural Language Processing (NLP) is a fascinating field. It helps computers understand human language!"

# Step 4: Preprocessing function
def preprocess_text_spacy(text):
    doc = nlp(text.lower())
    tokens = [token.lemma_ for token in doc if not token.is_stop and not token.is_punct]
    return tokens

# Step 5: Run preprocessing
processed_tokens = preprocess_text_spacy(text)
print("Processed Tokens:", processed_tokens)